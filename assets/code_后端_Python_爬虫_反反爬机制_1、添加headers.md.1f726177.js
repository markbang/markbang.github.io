import{_ as s,o as e,c as a,Q as n}from"./chunks/framework.d084db19.js";const g=JSON.parse('{"title":"headers的参数","description":"","frontmatter":{},"headers":[],"relativePath":"code/后端/Python/爬虫/反反爬机制/1、添加headers.md","filePath":"code/后端/Python/爬虫/反反爬机制/1、添加headers.md","lastUpdated":1700061697000}'),o={name:"code/后端/Python/爬虫/反反爬机制/1、添加headers.md"},p=n(`<h1 id="headers的参数" tabindex="-1">headers的参数 <a class="header-anchor" href="#headers的参数" aria-label="Permalink to &quot;headers的参数&quot;">​</a></h1><p>在<code>requests.get()</code>方法中，后面有关反爬的参数，其中就有headers，使用方法也很简单，<code>headers=一个字典</code>这个字典用来储存一些参数，伪造请求头来让网站认为是真人访问，而不是机器人。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">headers </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> {</span></span>
<span class="line"><span style="color:#E1E4E8;">  			</span><span style="color:#9ECBFF;">&#39;Referer&#39;</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">&#39;具体的Referer&#39;</span><span style="color:#E1E4E8;">,</span></span>
<span class="line"><span style="color:#E1E4E8;">            </span><span style="color:#9ECBFF;">&#39;User-Agent&#39;</span><span style="color:#E1E4E8;">: </span><span style="color:#9ECBFF;">&#39;具体的user-agent&#39;</span><span style="color:#E1E4E8;">,</span></span>
<span class="line"><span style="color:#E1E4E8;">    		</span><span style="color:#9ECBFF;">&#39;cookie&#39;</span><span style="color:#E1E4E8;">:</span><span style="color:#9ECBFF;">&#39;具体的cookie&#39;</span></span>
<span class="line"><span style="color:#E1E4E8;">    }</span></span>
<span class="line"><span style="color:#E1E4E8;">requests.get(url,</span><span style="color:#FFAB70;">headers</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">headers)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">headers </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> {</span></span>
<span class="line"><span style="color:#24292E;">  			</span><span style="color:#032F62;">&#39;Referer&#39;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&#39;具体的Referer&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#032F62;">&#39;User-Agent&#39;</span><span style="color:#24292E;">: </span><span style="color:#032F62;">&#39;具体的user-agent&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">    		</span><span style="color:#032F62;">&#39;cookie&#39;</span><span style="color:#24292E;">:</span><span style="color:#032F62;">&#39;具体的cookie&#39;</span></span>
<span class="line"><span style="color:#24292E;">    }</span></span>
<span class="line"><span style="color:#24292E;">requests.get(url,</span><span style="color:#E36209;">headers</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">headers)</span></span></code></pre></div><h2 id="user-agent" tabindex="-1">User-Agent <a class="header-anchor" href="#user-agent" aria-label="Permalink to &quot;User-Agent&quot;">​</a></h2><p>对于User-Agent想必大家都不陌生，这是爬虫的第一步，大部分网站都有检查User-Agent，设置它很简单，就是打开开发者工具，在网络请求中找到复制粘贴即可。因为User-Agent一般都是固定的，里面包含的只是一些浏览器型号之类的，目的是确保你这个请求是真人，所以<code>my_fake_useragent</code>库也应运而生。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> my_fake_useragent </span><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> UserAgent</span></span>
<span class="line"><span style="color:#E1E4E8;">headers </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> {</span><span style="color:#9ECBFF;">&#39;User-Agent&#39;</span><span style="color:#E1E4E8;">: UserAgent(</span><span style="color:#FFAB70;">family</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;chrome&#39;</span><span style="color:#E1E4E8;">).random()}</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> my_fake_useragent </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> UserAgent</span></span>
<span class="line"><span style="color:#24292E;">headers </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> {</span><span style="color:#032F62;">&#39;User-Agent&#39;</span><span style="color:#24292E;">: UserAgent(</span><span style="color:#E36209;">family</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;chrome&#39;</span><span style="color:#24292E;">).random()}</span></span></code></pre></div><p>按照这个方式就可以随机User-Agent，更加方便而且会解决一些User-Agent反爬机制。</p><h2 id="cookie" tabindex="-1">cookie <a class="header-anchor" href="#cookie" aria-label="Permalink to &quot;cookie&quot;">​</a></h2><p>cookie想必大家也很熟悉，cookie就是你在该网站上的身份信息，将你的cookie展示出来，服务器就会知道这是你，然后提供相关服务。</p><h2 id="referer" tabindex="-1">Referer <a class="header-anchor" href="#referer" aria-label="Permalink to &quot;Referer&quot;">​</a></h2><p>Referer与防盗链有关(防盗链：溯源，当前本次请求的上一级是谁 A -&gt;B -&gt;C )添加Referer就是确定是不是根据它所要的网站跳转到请求网站的，如果不是，则拒绝访问。例如一些视频网站的视频网址，如果不是从视频网站跳转过去，大部分可能就是拒绝请求或者返回一个假响应。</p><p>这里我会拿豆瓣做一个实例解析，感兴趣的可以去看看，<a href="./.html">链接</a>。</p><h2 id="content-type" tabindex="-1">Content-type <a class="header-anchor" href="#content-type" aria-label="Permalink to &quot;Content-type&quot;">​</a></h2><p>Content-type是</p><h1 id="普通参数" tabindex="-1">普通参数 <a class="header-anchor" href="#普通参数" aria-label="Permalink to &quot;普通参数&quot;">​</a></h1><p>在浏览器开发者模式中，我们不光只看到前面所提到的那几个参数，还有很多很多其它的参数，那具体的一个网站我怎么知道要添加哪些参数呢？</p><p>普通网站一般添加一个User-Agent就行了，需要账号信息的就再加cookie，剩下的情况就很少见了，遇到是都试一试就行。（这里还有一个万能方法，没错，就是用<strong>selenium</strong>模拟，但写起来比较麻烦）所以建议还是先试试能不能行，<strong>selenium</strong>作为下策。</p>`,17),l=[p];function t(r,c,i,y,E,d){return e(),a("div",null,l)}const u=s(o,[["render",t]]);export{g as __pageData,u as default};
